<html xmlns="http://www.w3.org/1999/xhtml">
<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <meta http-equiv="Content-Style-Type" content="text/css"></meta>
  <meta name="generator" content="pandoc"></meta>
  <meta name="author" content="Jason Grout"></meta>
  <title>Applied Linear Algebra Notes</title>
  <link rel="stylesheet" href="book.css" type="text/css"></link>
  <script src="https://d3eoax9i5htok0.cloudfront.net/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
  <meta name="viewport" content="width=device-width"></meta>
  
  <script src="http://aleph.sagemath.org/static/jquery.min.js"></script>
  <script src="http://aleph.sagemath.org/static/embedded_sagecell.js"></script>
  <script>
  $(function () {
  
  // For some reason, MathJax gets messed up if we don't put this timeout.
  // my guess is it has to do with us appending script tags to the end
  // the head element, but I don't know.
  setTimeout(function() {
  sagecell.loadMathJax=false;
  sagecell.makeSagecell({inputLocation: '.asagecell'});
  }, 1000);
  
  //console.log(MathJax);
  });
  </script>
  <script>
  $(function() {
  $(document).on("click", '.collapsible .title', function(e) {
  var body = $(e.target.parentElement).find('.body').slideToggle("fast").find('.CodeMirror').each(function(i, e) {e.CodeMirror.refresh()});
  });
  });
  </script>
</head>
<body>
<div id="header">
<h1 class="title">Applied Linear Algebra Notes</h1>
<h2 class="author">Jason Grout</h2>
<h3 class="date">Fall 2012</h3>
</div>
<div id="TOC">
<ul>
<li><a href="#preface">Preface</a></li>
<li><a href="#class-plans">Class Plans</a><ul>
<li><a href="#aug-2012">27 Aug 2012</a></li>
<li><a href="#aug-2012-1">29 Aug 2012</a></li>
<li><a href="#sep-2012">05 Sep 2012</a></li>
<li><a href="#sep-2012-1">10 Sep 2012</a><ul>
<li><a href="#prepare">Prepare</a></li>
<li><a href="#class">Class</a></li>
</ul></li>
<li><a href="#sep-2012-2">12 Sep 2012</a><ul>
<li><a href="#prepare-1">Prepare</a></li>
<li><a href="#class-1">Class</a></li>
</ul></li>
</ul></li>
<li><a href="#lecture-1-matrix-vector-multiplication">Lecture 1: Matrix-vector multiplication</a></li>
<li><a href="#lecture-2-orthogonal-vectors-and-matrices">Lecture 2: Orthogonal Vectors and Matrices</a></li>
<li><a href="#lecture-3-norms">Lecture 3: Norms</a></li>
<li><a href="#lecture-4-the-singular-value-decomposition">Lecture 4: The Singular Value Decomposition</a></li>
<li><a href="#lecture-5-more-on-the-svd">Lecture 5: More on the SVD</a></li>
</ul>
</div>
<div class="frontmatter">



<div class="html">
\(\newcommand{\norm}[1]{\lVert #1\rVert }\) \(\newcommand{\norms}[1]{\left\lVert #1\right\rVert }\) \(\newcommand{\abs}[1]{\lvert #1\rvert }\) \(\newcommand{\abss}[1]{\left\lvert #1\right\rvert }\) \(\newcommand{\rank}{\operatorname{rank}}\)
</div>
<div class="html">
<a rel="license" href="http://creativecommons.org/licenses/by-sa/3.0/us/deed.en_US"><img alt="Creative Commons License" style="border-width:0" src="http://i.creativecommons.org/l/by-sa/3.0/us/88x31.png"></img></a><br></br><span xmlns:dct="http://purl.org/dc/terms/" property="dct:title">Applied Linear Algebra Notes</span> by <a xmlns:cc="http://creativecommons.org/ns#" href="https://github.com/jasongrout/applied-linear-algebra" property="cc:attributionName" rel="cc:attributionURL">Jason Grout</a> is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/3.0/us/deed.en_US">Creative Commons Attribution-ShareAlike 3.0 United States License</a>.
</div>

<h1 id="preface"><a href="#TOC">Preface</a></h1>
<p>The chapter titles in these notes correspond with the chapter titles in the book <a href="http://people.maths.ox.ac.uk/trefethen/text.html"><em>Numerical Linear Algebra</em></a> by Trefethen and Bau, published by SIAM. The sections below are labeled “Lectures” because the chapters in the book are labeled “Lectures”, but they may not correspond with single class periods.</p>
<div class="html">
A nicely typeset version of these notes is <a href="http://sage.math.washington.edu/home/jason/applied-linear-algebra.pdf">here</a>.
</div>

<p>An online version of these notes is available that includes some enhancements from <a href="http://www.sagemath.org">Sage</a>.</p>
<p><strong>Make sure to read and understand each chapter as we cover it in class.</strong></p>
<h1 id="class-plans"><a href="#TOC">Class Plans</a></h1>
<h2 id="aug-2012"><a href="#TOC">27 Aug 2012</a></h2>
<ol>
<li><p>Some highlights of why studying applied, numerical linear algebra is important.</p>
<ul>
<li>Calculating a determinant is both impossibly hard and numerically bad when using cofactor expansion. Instead, use LU decomposition or similar</li>
<li>Calculating eigenvalues using the characteristic polynomial is bad, since it involves both a determinant and polynomial root-finding (numerically unstable). See <a href="http://en.wikipedia.org/wiki/Wilkinson's_polynomial">Wilkinson’s polynomial</a>.</li>
</ul>
<div class="collapsible"><div class="title">Sage Cell</div><div class="body"><div class="asagecell">
wilkinson = prod((x-i) for i in [1..20]).polynomial(QQ)
x=wilkinson.variables()[0]
eps=2^-31
c=-210
@interact
def _(precision=slider(40,100,1,default=53), coefficient=slider([c-eps..c-eps/20,step=float(eps/20)]+[c..c+eps,step=float(eps/20)],default=c)):
    R = ComplexField(precision)
    perturbed = wilkinson.change_ring(R)+(R(coefficient)-c)*x^19
    original_roots = [1..20]
    perturbed_roots = [i[0] for i in perturbed.roots()]
    p=points([list(CC(i)) for i in perturbed_roots],color='red',size=50)
    p+=points([i,0] for i in [1..20])
    # match up roots
    rootlist=[]
    for r in [1..20]:
        # find the closest root left
        matching_root = min([[i, abs(r-i),index] for index,i in enumerate(perturbed_roots)], key=lambda x: x[1])
        rootlist.append([r, matching_root[0], matching_root[1]])
        perturbed_roots.pop(matching_root[2])

    html("Changing the $x^{19}$ term from $-210x^{19}$ to $%sx^{19}$ gives the following differences in roots"%R(coefficient))
    maxerror = max(i[2] for i in rootlist)
    html("Estimate of maximum error: %s; %s times the coefficient perturbation"%(maxerror, R(maxerror)/(R(coefficient)+210)))
    p.show(ymin=-1,ymax=1)

    html.table(rootlist,
    header=["Original root", "Perturbed root", "Distance"])

</div></div></div></li>
<li><p>Review of key concepts from linear algebra (see exercises).</p></li>
</ol>
<h2 id="aug-2012-1"><a href="#TOC">29 Aug 2012</a></h2>
<ol>
<li><p>Present the rest of Exercise 1.1–1.3</p></li>
<li><p>Discuss the connection between matrices and linear transformations, including invertible matrices.</p></li>
<li><p>Discuss coordinates briefly.</p></li>
</ol>
<h2 id="sep-2012"><a href="#TOC">05 Sep 2012</a></h2>
<ol>
<li><p>Present the rest of the exercises for Lecture 1</p></li>
<li><p>Complex numbers</p></li>
<li><p>Start working on exercises for Lecture 2.</p></li>
</ol>
<h2 id="sep-2012-1"><a href="#TOC">10 Sep 2012</a></h2>
<h3 id="prepare"><a href="#TOC">Prepare</a></h3>
<ol>
<li><p>Hand in problems from Lecture 1.</p></li>
<li><p>Read chapter 2</p></li>
<li><p>Do as many from 2.1–2.3, 2.5–2.7 as you can</p></li>
</ol>
<h3 id="class"><a href="#TOC">Class</a></h3>
<ol>
<li><p>Present Exercise 1.13, 1.15 (text exercises 1.1, 1.4). Emphasize how to get the matrices in 1.13 (do the operations on identity matrices).</p></li>
<li><p>Introduce orthogonality. Orthogonality helps tremendously with two different problems:</p>
<ol>
<li><p>Sensitivity. If a system of equations is solving lines that are very close to each other, then small changes in the input can drastically change the solutions.</p></li>
<li><p>Efficiency. Having an orthogonal basis makes it <em>much</em> easier to find coordinate vectors. It’s a dot product, rather than solving a system of equations.</p></li>
</ol></li>
<li><p>Present exercises 2.1–2.3, 2.5–2.7</p></li>
</ol>
<h2 id="sep-2012-2"><a href="#TOC">12 Sep 2012</a></h2>
<h3 id="prepare-1"><a href="#TOC">Prepare</a></h3>
<ol>
<li>Do as many from 2.8, 2.10-2.17 as you can</li>
</ol>
<h3 id="class-1"><a href="#TOC">Class</a></h3>
<ol>
<li><p>Show equations (2.9) and (2.10) in the text are right.</p></li>
<li><p>Introduction to Sage</p></li>
<li><p>Work out 2.9 in Sage</p></li>
</ol>
</div>
<div class="mainmatter">
<h1 id="lecture-1-matrix-vector-multiplication"><a href="#TOC">Lecture 1: Matrix-vector multiplication</a></h1>
<p>This should primarily be a review of concepts from the first linear algebra class, though there are probably examples you haven’t seen before.</p>
<p>Practice interpreting the summation notation, like in equation 1.1 and in other places in the chapter. This book uses such summation notation a lot.</p>
<div class="definition">
<p>A <span class="term">linear combination</span> of some vectors is a sum of scalar multiples of the vectors (i.e., \(c_1\vec v_1+c_2\vec v_2+\cdots+c_n\vec v_n\)). A <span class="term">nontrival linear combination</span> is a linear combination with at least one nonzero scalar coefficient.</p>
<p>The <span class="term">span</span> of some vectors is the set of all linear combinations of the vectors (this is a set of vectors). A set of vectors is <span class="term">linearly independent</span> if none of the vectors can be written as a linear combination of the others. Equivalently, a set of vectors \(\{\vec v_1, \vec v_2, \ldots, \vec v_n\}\) is <span class="term">linearly independent</span> if there is any nontrivial linear combination that equals the zero vector (i.e., there is some nonzero coefficients \(c_i\) so that \(c_1\vec v_1+c_2\vec v_2+\cdots +c_n\vec v_n=\vec 0\)).</p>
A <span class="term">vector space</span> is the span of some vectors. Equivalently, a <span class="term">vector space</span> is a set of vectors that is closed under linear combinations (i.e., any linear combinations of any vectors in the set are always also in the set). A <span class="term">basis</span> for a vector space is a linearly independent set of vectors that spans the space. The <span class="term">dimension</span> of the space is the size of a basis (all bases of a space have the same size).
</div>

<div class="exercise"> 
<p>Which of the following sets of vectors are vector spaces? If not, give a reason why it is not (i.e., take some vectors in the set, and give a linear combination of those vectors that is not in the set). For each vector space, give two different bases and the dimension of the vector space.</p>
<ol>
<li>\(\{ (1,2,3)\}\)</li>
<li>\(\{c(-1,0,1)+(2,1,3)\mid c\in\mathbb{R}\}\)</li>
<li>\(\{(x,y) \mid x\geq 0 \text{ and } y\geq 0\}\): all vectors in \(\mathbb{R}^2\) that have only positive components</li>
<li>\(\{(x,y)\mid x=0 \text{ or } y=0\}\): all vectors in \(\mathbb{R}^2\) that are on either the \(x\) or \(y\) axes</li>
<li>\(\{(x,y,z)\mid \sqrt{x^2+y^2+z^2}\leq 1\}\): all vectors in \(\mathbb{R}^3\) that have length less than or equal to 1</li>
<li>\(\{c(1,2,3) \mid c\in\mathbb{R}\}\): all multiples (i.e., linear combinations) of the vector \((1,2,3)\). The endpoints of these vectors form a line through the origin.</li>
<li>\(\{(0,0,0)\}\): just the zero vector (i.e., all linear combinations of the zero vector). This vector space has only one vector, as opposed to the others which have an infinite number of vectors.</li>
<li>\(\{c_1(-1,0,1)+c_2(2,1,2) \mid c_1,c_2\in\mathbb{R}\}\): all linear combinations of \((-1,0,1)\) and \((2,1,2)\). The endpoints of these vectors form a plane through the origin.</li>
<li>\(\{c_1(-1,0,1)+c_2(2,1,2)+c_3(-4,-1,0) \mid c_1,c_2,c_3\in\mathbb{R}\}\): all linear combinations of \((-1,0,1)\), \((2,1,2)\), and \((-4,-1,0)\). Hint: Since the third vector \((-4,-1,0)\) is actually a linear combination of \((-1,0,1)\) and \((2,1,2)\), \((-4,-1,0)=2(-1,0,1)-(2,1,2)\), any linear combination of the three vectors can actually be written as a linear combination of just the first two vectors. For example, \[\begin{align*}
3(-1,0,1)-2(2,1,2)+2(-4,-1,0)&amp;=3(-1,0,1)-2(2,1,2)+2(2(-1,0,1)-(2,1,2))\\
&amp;=7(-1,0,1)-4(2,1,2).
\end{align*}\]</li>
<li>The set of all polynomials with degree at most 3.</li>
<li>The set of all polynomials with degree equal to 3.</li>
<li>The set of all polynomials.</li>
<li>The set of all 2 by 2 matrices.</li>
<li>The set of all invertible 3 by 3 matrices.</li>
<li>The set of all diagonal 3 by 3 matrices.</li>
<li>The set of all 3 by 3 matrices that are upper triangular.</li>
<li>The set of all 3 by 3 symmetric matrices.</li>
<li>The set of all continuous functions.</li>
<li>The set of all continuous functions such that \(f(0)=0\).</li>
<li>The set of all functions with continuous first derivatives.</li>
</ol>
</div>

<div class="definition">
<p>A linear transformation \(T\colon V\to W\) is a function from one vector space to another that:</p>
<ul>
<li>preserves vector addition: \(T(\vec x+\vec y) = T(\vec x)+T(\vec y)\)</li>
<li>preserves scalar multiplication: \(T(c\vec x) = cT(\vec x)\).</li>
</ul>
</div>

<div class="exercise">
    
Let \(A\) be a matrix. Prove that \(T(\vec x)=A\vec x\) is a linear transformation. [Hint: show that it satisfies the two criteria for a linear transformation at the bottom of page 3 of the text.]
</div>

<div class="exercise">
Find the matrix \(A\) for the linear transformation \(T((a,b)) = (2a-3b, 5a)\) so that \(T(\vec x)=A\vec x\).
</div>


<p>You can check your work with Sage (and also see how Sage creates vectors and matrices) by playing with the example below. Go ahead and change the matrix to your matrix.</p>
<div class="asagecell">
var('a,b')
v=vector([a,b])
A=matrix(QQ,[[1,2],[3,4]])
print A
print A*v
</div>
<p>When you get to this point, ask me to help you draw a diagram connecting the column space and null space of a matrix \(A\) and the linear transformation \(T(\vec x)=A\vec x\).</p>
<div class="exercise">
Show that linear transformations preserve linear combinations. In other words, show that if \(T\) is a linear transformation, then \[T(c_1\vec v_1+c_2\vec v_2+\cdots+c_n\vec v_n) = c_1T(\vec v_1)+c_2 T(\vec v_2)+\cdots+c_n T(\vec v_n).\]
</div>

<div class="exercise"> 
Suppose \(T\colon \mathbb{R}^2\to \mathbb{R}^2\) is a linear transformation. Suppose also that \(\vec u,\vec v\in\mathbb{R}^2\). Suppose also that \(T(\vec u)=(1,2)\) and \(T(\vec v)=(-3,4)\). What is \(T(3\vec u+2\vec v)\)?
</div>

<div class="exercise">
<p>Suppose \(T\colon \mathbb{R}^2\to \mathbb{R}^2\) is a linear transformation that does the following operations in order:</p>
<ol>
<li>rotates vectors by 90 degrees clockwise, then</li>
<li>flips the vectors over the \(y\) axis, then</li>
<li>stretches things horizontally by a factor of 3.</li>
</ol>
<p>Answer the following questions:</p>
<ol style="list-style-type: lower-alpha">
<li>What is \(T((1,0))\)?</li>
<li>What is \(T((0,1))\)?</li>
<li>What is \(T(3(1,0)+2(0,1))\)?</li>
<li>What is \(T((a,b))\)?</li>
<li>What is the matrix \(A\) representing \(T\), so that \(T(\vec x)=A\vec x\)?</li>
</ol>
</div>

<p>Check your work to the above exercise by modifying \(A\) and \(\vec v\) below and confirming your answers in the first parts of the problem.</p>
<div class="asagecell">
v=vector([1,2])
A=matrix(QQ,[[1,2],[3,4]])
print A*v
</div>
<div class="definition"> 
A <span class="term">coordinate vector</span> \([\vec v]_\mathcal{B}\) relative to an ordered basis \(\mathcal{B}\) is a vector of coefficients of the linear combination of basis elements equaling \(\vec v\). In other words, if \(\mathcal{B}=\{b_1,b_2,\ldots,b_n\}\) is a basis, then the coordinate vector for a vector \(\vec v=c_1\vec b_1+c_2\vec b_2+\cdots+c_n\vec b_n\) is \([\vec v]_\mathcal{B}=(c_1,c_2,\ldots,c_n)_\mathcal{B}\).
</div>

<div class="exercise"> 
<p>Let \(\mathcal{B}=\{1,x,x^2\}\) be a basis for \(P_2\), the set of all polynomials with degree at most 2.</p>
<ol>
<li>Let \(p=2x-x^2\) be a vector in \(P_3\). What is the coordinate vector \([p]_\mathcal{B}\)?</li>
<li>What is the polynomial represented by the coordinate vector \((2,3,-4)_\mathcal{B}\)?</li>
</ol>
</div>


<p>One of the huge advantages of using coordinate vectors is that linear transformations on finite dimensional vector spaces can be computed by multiplying a matrix and a coordinate vector.</p>
<div class="exercise">
\(P_3\) is the vector space of polynomials with degree at most 3. Let \(T\colon P_3\to\mathbb{R}^3\) be the linear transformation \(T(p)=(p(x=-1), p(x=0), p(x=1))\) (i.e., evaluate \(p\) at \(x=-1\), \(x=0\), and \(x=1\)). For example, \(T(3+x-2x^2+5x^3)=(3-1-2-5, 3, 3+1-2+5)=(-5,3,7)\). Let \(\mathcal{B}=\{1,x,x^2,x^3\}\) be a basis for \(P_3\). Find a matrix representing \(T\) relative to \(\mathcal{B}\) and the standard basis on \(\mathbb{R}^3\).
</div>

<div class="asagecell">
v=vector([3,1,-2,5])
#fill in A
A=matrix(QQ, [[],[],[]])
A*v # should be (-5,3,7), according to our example above.
</div>
<div class="exercise">
Write \(A\begin{pmatrix} 1\\2\\3\end{pmatrix}\) as a linear combination of the columns of \(A\).
</div>

<div class="exercise">
<p>Do the following.</p>
<ol>
<li>Express the columns of \(AB\) as a linear combination of columns of \(A\)</li>
<li>Express the rows of \(AB\) as a linear combination of rows of \(B\).</li>
<li>Express the entries of \(AB\) as dot products of rows of \(A\) and columns of \(B\).</li>
<li>What if \(B\) is a matrix of all ones? What does \(AB\) compute then? What does \(BA\) compute?</li>
</ol>
</div>
<p>Check your answer to the last part of the question above about an all-ones matrix.</p>
<div class="asagecell">
A=random_matrix(QQ, 3);
B=ones_matrix(QQ,3)
print A
print
print A*B
</div>
<div class="exercise">
Give short reasons why the text’s Theorem 1.3 parts (a), (b), (c), and (d) are equivalent.
</div>

<div class="exercise">
<p>Let \[A=\begin{bmatrix}1&amp;3\\2&amp;5\end{bmatrix},\quad
A^{-1}=\begin{bmatrix}-5&amp;3\\2&amp;-1\end{bmatrix}.\] Let \(\mathcal{B}=\{(1,2),\, (3,5)\}\) be a basis for \(\mathbb{R}^2\).</p>
<ol>
<li><p>Use \(A\) to compute the vectors with coordinate vectors \((1,0)_\mathcal{B}\), \((0,1)_\mathcal{B}\), and \((2,3)_\mathcal{B}\).</p></li>
<li><p>Use \(A^{-1}\) to compute the coordinate vectors \([(-3,-4)]_\mathcal{B}\) and \([(a,b)]_\mathcal{B}\).</p></li>
</ol>
</div>

<p>When you get to this point, ask me to help you modify the diagram we drew above in order to deal with linear transformations that correspond to invertible matrices.</p>
<div class="exercise">
Text exercise 1.1
</div>

<div class="exercise">
Text exercise 1.3
</div>

<div class="exercise">
Text exercise 1.4
</div>


<h1 id="lecture-2-orthogonal-vectors-and-matrices"><a href="#TOC">Lecture 2: Orthogonal Vectors and Matrices</a></h1>
<p>The set of complex numbers is denoted \(\mathbb{C}\). The conjugate of the complex number \(z=a+bi\) is \(\bar z = a-bi\).</p>

<div class="exercise">
Show that if \(z\bar z = z^2\), then \(z\) must be a real number (i.e., the imaginary part of \(z\) is 0).
</div>

<div class="exercise">
<p>Answer the following.</p>
<ol>
<li>Let \(A=\begin{bmatrix}4&amp;4+i&amp;2+i\\1-i&amp;2-i&amp;5\end{bmatrix}\). What is \(A^*\)? Is \(A\) hermitian?</li>
<li>Let \(B=\begin{bmatrix}2&amp;4+2i\\4-2i&amp;5\end{bmatrix}\). What is \(B^*\)? Is \(B\) hermitian?</li>
</ol>
</div>

<div class="exercise">

<p>Answer the following.</p>
<ol>
<li>What must be true about diagonal entries of hermitian matrices?</li>
<li>Prove that \(AA^*\) is always hermitian.</li>
</ol>
</div>

<div class="asagecell">
# Use CDF for complex matrices
A=matrix(CDF, [[4,4+I,2+I],[1-I,2-I,5]])
print A.H # this is A^*
print A.is_hermitian()
print A.H==A
</div>
<div class="exercise">
Give an example showing that the inner product on \(\mathbb{C}^2\) is bilinear. [Hint: compute explicitly each side of the 3 defining equations defining bilinearity.]
</div>

<div class="exercise">
Give an example showing that the (2,1) element of \((AB)^*\) is the same as the (2,1) element of \(B^*A^*\).
</div>

<div class="exercise">
<p>Answer the following.</p>
<ol>
<li>Prove that \((AB)^{-1}=B^{-1}A^{-1}\).</li>
<li>Prove that \((A^*)^{-1}=(A^{-1})^*\).</li>
</ol>
</div>

<div class="exercise">
<p>Answer the following.</p>
<ol>
<li>What is the angle between \((1,2)\) and \((2,-1)\)? Are these vectors orthogonal? [Hint: use equation (2.3) for the first question.]</li>
<li>Is the set \(\{(1/\sqrt{2}, i/\sqrt{2}), (1+i,-1)\}\) orthonormal? Is it linearly independent? Remember that now, scalars can be complex numbers.</li>
</ol>
</div>

<div class="exercise">
Give the reasons why the second equality in equation (2.7) in the text is true.
</div>

<div class="exercise">
Use the Sage cell below, or the Sage notebook, to compute the two decompositions of \(v\) given in equation (2.7).
</div>



<div class="asagecell">
A=matrix(RDF, [[1,4,3],[2,3,6],[-1,-4,3]])
Q,R=A.QR()

# check that Q is unitary, or in other words, that the columns of Q are
# an orthonormal basis.

(q1,q2,q3) = Q.columns()


# nicer columns
q1=vector(QQ,[2,-2,1])/3
q2=vector(QQ,[2,1,-2])/3
q1=vector(QQ,[1,2,2])/3

</div>


<div class="exercise">
Text exercise 2.1
</div>

<div class="exercise">
Text exercise 2.2
</div>

<div class="exercise">
Text exercise 2.3
</div>

<div class="exercise">
Text exercise 2.4. Additionally, what can be said about the determinant of a unitary matrix?
</div>

<div class="exercise"> 
Prove that if \(\lambda\) is an eigenvalue of \(A\) with eigenvector \(\vec x\), then \(\lambda^2\) is an eigenvalue of \(A^2\) with the same eigenvector \(\vec x\). [Hint: in mathematical notation, if \(A\vec x=\lambda x\) for some nonzero vector \(\vec x\), then show that \(A^2\vec x = \lambda^2 x\)].
</div>

<div class="exercise">
Text exercise 2.5. [Hint: For any matrix \(A\) , \((I+A)(I-A)=(I-A)(I+A)\). Prove this hint if you use it.]
</div>

<div class="exercise">
Text exercise 2.6
</div>

<div class="exercise">
Text exercise 2.7
</div>


<h1 id="lecture-3-norms"><a href="#TOC">Lecture 3: Norms</a></h1>
<p>You can use Sage examples to explore <a href="http://interact.sagemath.org/node/58">unit balls</a> and <a href="http://interact.sagemath.org/node/27%20induced%20matrix%20norms">induced matrix norms</a>.</p>
<div class="exercise">

<p>Let \(\vec v = (1,\,2+3i,\, -4i)\). Compute \(\norm{\vec v}_1\), \(\norm{\vec v}_2\), \(\norm{\vec v}_4\), and \(\norm{\vec v}_\infty\). Check your work in Sage.</p>
<div class="asagecell">
# An example of how to compute norms of a vector in Sage.
v=vector(CDF, [1,-2*I])
print v.norm(p=3)
print v.norm(p=Infinity)
</div>
</div>

<div class="exercise">
<p>Norms give us a way to associate a number with a vector. The number may represent something other than physical distances.</p>
<p>A manufacturing robot has costs associated with moving the tip of its arm. Moving east or west costs $2/meter, moving north or south costs $3/meter, and moving up or down costs $5/meter. A vector \(\vec v=(a,b,c)\) represents moving \(a\) meters east, \(b\) meters north, and \(c\) meters up (each number can be negative to move the opposite direction).</p>
<ol>
<li><p>Come up with a norm formula that gives the cost for moving along a vector \((a,b,c)\).</p></li>
<li><p>What is the norm of \((1,2,3)\) and \((2,-1,3)\)?</p></li>
</ol>
</div>

<div class="exercise">

<p>Text exercise 3.1.</p>
</div>

<div class="exercise">

<p>The text claims in paragraph 3 of page 19 that condition (3) of equation (3.1) implies that the action of \(A\) is determined by its action on the unit vectors of the domain. In other words, to find the maximum stretch that \(A\) causes, you only have to look at the unit vectors of the domain. Explain why this is true.</p>
</div>






<div class="exercise">

<p>Let \(A=[a_1\,a_2\,\cdots\,a_n]\) be an \(n\) by \(n\) matrix with columns \(a_1,a_2,\ldots,a_n\). Let \(x\in \mathbb{C}^n\) be a vector inside the diamond-shaped 1-norm unit ball in \(\mathbb{C}^n\) (i.e., \(\sum_{j=1}^n\abs{x_j}\leq 1\)). Explain why each of the following inequalities is true. [Hint: these inequalities are from the line between equations (3.8) and (3.9) in the text.]</p>
<p>\[\norm{Ax}_1 = \norms{\sum_{j=1}^n x_ja_j}_1 \leq
\sum_{j=1}^n\abs{x_j}\norm{a_j}_1\leq \max_{1\leq j\leq n}\norm{a_j}_1\]</p>
</div>

<div class="exercise">
Prove equation (3.10) in the text is true.
</div>



<div class="exercise">
Explain why (3.12) is true, given that equation (2.3) is true.
</div>

<div class="exercise">
Explain why each equality or inequality in equation (3.13) is true.
</div>

<div class="exercise">
<p>Explain why these inequalities that occur just before equation (3.14) are true:</p>
\[\norm{ABx}_{(\ell)}\leq \norm{A}_{(\ell,m)} \norm{Bx}_{(m)}\leq \norm{A}_{(\ell,m)}\norm{B}_{(m,n)}\norm{x}_{(n)}.\]
</div>

<div class="exercise">
Give an example showing that the inequality in equation (3.14) is not tight. In other words, give an induced matrix norm and explicit matrices \(A\) and \(B\) so that \(\norm{AB}_{(\ell,n)}\neq \norm{A}_{(\ell,m)}\norm{B}_{(m,n)}\).
</div>

<div class="exercise">
Prove equation (3.18).
</div>

<div class="exercise">
<p>Do the following.</p>
<ol>
<li>Either find matrices \(A\) and \(B\) so that \(\norm{AB}_F&lt;\norm{A}_F\norm{B}_F\) or show that such an example does not exist.</li>
<li>Either find matrices \(A\) and \(B\) so that \(\norm{AB}_F=\norm{A}_F\norm{B}_F\) or show that such an example does not exist.</li>
</ol>
</div>

<div class="exercise">
Show that if \(Q\) is a unitary matrix, then \(\norm{QA}_F=\norm{A}_F\). [Hint: see Theorem 3.1.]
</div>

<div class="exercise">
Text exercise 3.2
</div>

<div class="exercise">
Text exercise 3.3
</div>

<p>You can calculate matrix norms in Sage. You might use this to check some of your examples.</p>
<div class="asagecell">
# An example of how to compute norms of a matrix in Sage.
A=matrix(CDF, [[1,-2*I], [-I, 3]])
print A.norm(p=1)
print A.norm(p=2)
print A.norm(p=Infinity)
print A.norm(p='frob')
</div>
<h1 id="lecture-4-the-singular-value-decomposition"><a href="#TOC">Lecture 4: The Singular Value Decomposition</a></h1>
<p>You can use a Sage <a href="http://interact.sagemath.org/node/60">interact</a> example to explore the SVD for invertible 2 by 2 matrices. You can also compute the SVD in Sage.</p>
<div class="asagecell">
# An example of how to compute the SVD of a matrix
A=matrix(CDF, [[1,-2*I], [-I, 3]])
U,S,V = A.SVD()
print U
print
print S
print
print V
print
print A-U*S*V.H # should be very close to the zero matrix
</div>
<div class="exercise">
Using the definition of the SVD given in equation (4.4), show that the largest singular value \(\sigma_1\) of a matrix \(A\) is equal to \(\norm{A}_2\).
</div>

<div class="exercise">
Text exercise 4.1 (by hand—so show your work and reasoning). [Hint: You might first determine a vectors that are stretched the most and second-most by the matrix. Then figure out the matrices that will transform those vectors to \((1,0)\) and \((0,1)\), then stretch appropriately, then rotate them to the final positions. Remember that singular values must be nonnegative. Another way to approach the problem is to use equation (4.1)—figure out which vectors are scaled the most and second-most, and where they go. Check your answer by computing \(U\Sigma V^*\).]
</div>

<div class="exercise">
Show that the product of two unitary matrices \(U\) and \(V\) is also unitary.
</div>

<div class="exercise">
Text exercise 4.2. [Hint: Find a way to express the relationship between \(A\) and \(B\) as matrix multiplication and other matrix operations.]
</div>

<div class="exercise">
Text exercise 4.4
</div>



<h1 id="lecture-5-more-on-the-svd"><a href="#TOC">Lecture 5: More on the SVD</a></h1>
<p>As mentioned in chapter 4, you can use a Sage <a href="http://interact.sagemath.org/node/60">interact</a> example to explore the SVD for invertible 2 by 2 matrices. You can also compute the SVD in Sage.</p>
<div class="asagecell">
# An example of how to compute the SVD of a matrix
A=matrix(CDF, [[1,-2*I], [-I, 3]])
U,S,V = A.SVD()
print U
print
print S
print
print V
print
print A-U*S*V.H # should be very close to the zero matrix
</div>
<div class="exercise">
    
Show that if \(B\) is an invertible matrix, then \(\rank(AB)=\rank(A)\) and \(\rank(BC)=\rank(C)\) for any matrices \(A\) and \(C\) that are the right size for multiplication to be defined. This is used in the proof of Theorem 5.1 (and a few other places as well).
</div>

<div class="exercise">

<p>Let \(A\) be a matrix and \(A_k=\sum_{j=1}^k \sigma_j u_j v_j^*\), as defined in equation (5.4). Explain why \(\norm{A-A_k}_2=\sigma_{k+1}\) if \(k\leq\rank(A)\). [Hint: see Theorem 5.3.]</p>
</div>

<div class="exercise">
<p>Let \[A=\begin{bmatrix} 1 &amp; 2 &amp; 3\\4 &amp; 5 &amp; 6\\-1 &amp; 2 &amp; 1\end{bmatrix}\].</p>
<ol>
<li><p>Write \(A\) as the sum of rank 1 matrices given in equation (5.3). Show explicitly the elements of the sum. You might use Sage to compute the SVD matrices.</p></li>
<li><p>Calculate the low-rank approximations \(A_1\) and \(A_2\) according to equation (5.4). Find the distance between \(A\) and each of \(A_1\) and \(A_2\), where distance is measured in the matrix 2-norm (i.e., find \(\norm{A-A_1}_2\) and \(\norm{A-A_2}_2\)). Compare these distances to the singular values of \(A\).</p></li>
<li><p>Explain why \(A_1\) and \(A_2\) are so special (i.e., tell us what Theorem 5.8 says is significant about \(A_1\) and \(A_2\) compared to \(A\)).</p></li>
</ol>
</div>

<div class="exercise">
Text exercise 5.1
</div>

<div class="exercise">
Text exercise 5.3
</div>

<p>If you want a challenge, do text exercise 5.2 and think about the consequences. Remind me to discuss this.</p>
</div>
</body>
</html>
