<html xmlns="http://www.w3.org/1999/xhtml">
<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <meta http-equiv="Content-Style-Type" content="text/css"></meta>
  <meta name="generator" content="pandoc"></meta>
  <meta name="author" content="Jason Grout"></meta>
  <title>Applied Linear Algebra</title>
  <link rel="stylesheet" href="book.css" type="text/css"></link>
  <script src="https://d3eoax9i5htok0.cloudfront.net/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
  <meta name="viewport" content="width=device-width"></meta>
  
  <script src="http://aleph.sagemath.org/static/jquery.min.js"></script>
  <script src="http://aleph.sagemath.org/static/embedded_sagecell.js"></script>
  <script>
  $(function () {
  
  // For some reason, MathJax gets messed up if we don't put this timeout.
  // my guess is it has to do with us appending script tags to the end
  // the head element, but I don't know.
  setTimeout(function() {
  sagecell.loadMathJax=false;
  sagecell.makeSagecell({inputLocation: '.asagecell'});
  }, 1000);
  
  //console.log(MathJax);
  });
  </script>
</head>
<body>
<div id="header">
<h1 class="title">Applied Linear Algebra</h1>
<h2 class="author">Jason Grout</h2>
<h3 class="date">Fall 2012</h3>
</div>
<div id="TOC">
<ul>
<li><a href="#preface">Preface</a></li>
<li><a href="#class-plans">Class Plans</a><ul>
<li><a href="#aug-2012">27 Aug 2012</a></li>
<li><a href="#aug-2012-1">29 Aug 2012</a></li>
<li><a href="#sep-2012">05 Sep 2012</a></li>
</ul></li>
<li><a href="#lecture-1">Lecture 1</a></li>
<li><a href="#draft-lecture-2-orthogonal-vectors-and-matrices">(DRAFT) Lecture 2: Orthogonal Vectors and Matrices</a><ul>
<li><a href="#in-class-activities">In-class activities</a></li>
</ul></li>
</ul>
</div>
<div class="frontmatter">
<h1 id="preface"><a href="#TOC">Preface</a></h1>
<p>The chapter titles in these notes correspond with the chapter titles in the book <a href="http://people.maths.ox.ac.uk/trefethen/text.html"><em>Numerical Linear Algebra</em></a> by Trefethen and Bau, published by SIAM. The sections below are labeled “Lectures” because the chapters in the book are labeled “Lectures”, but they may not correspond with single class periods.</p>
<div class="html">
A nicely typeset version of these notes is <a href="http://sage.math.washington.edu/home/jason/applied-linear-algebra.pdf">here</a>.
</div>

<p>An online version of these notes is available that includes some enhancements from <a href="http://www.sagemath.org">Sage</a>.</p>
<p><strong>Make sure to read and understand each chapter as we cover it in class.</strong></p>
<h1 id="class-plans"><a href="#TOC">Class Plans</a></h1>
<h2 id="aug-2012"><a href="#TOC">27 Aug 2012</a></h2>
<ol>
<li><p>Some highlights of why studying applied, numerical linear algebra is important.</p>
<ul>
<li>Calculating a determinant is both impossibly hard and numerically bad when using cofactor expansion. Instead, use LU decomposition or similar</li>
<li>Calculating eigenvalues using the characteristic polynomial is bad, since it involves both a determinant and polynomial root-finding (numerically unstable). See <a href="http://en.wikipedia.org/wiki/Wilkinson's_polynomial">Wilkinson’s polynomial</a>.</li>
</ul>
<div class="asagecell">
wilkinson = prod((x-i) for i in [1..20]).polynomial(QQ)
x=wilkinson.variables()[0]
eps=2^-31
c=-210
@interact
def _(precision=slider(40,100,1,default=53), coefficient=slider([c-eps..c-eps/20,step=float(eps/20)]+[c..c+eps,step=float(eps/20)],default=c)):
    R = ComplexField(precision)
    perturbed = wilkinson.change_ring(R)+(R(coefficient)-c)*x^19
    original_roots = [1..20]
    perturbed_roots = [i[0] for i in perturbed.roots()]
    # match up roots
    rootlist=[]
    for r in [1..20]:
        # find the closest root left
        matching_root = min([[i, abs(r-i),index] for index,i in enumerate(perturbed_roots)], key=lambda x: x[1])
        rootlist.append([r, matching_root[0], matching_root[1]])
        perturbed_roots.pop(matching_root[2])

    html("Changing the $x^{19}$ term from $-210x^{19}$ to $%sx^{19}$ gives the following differences in roots"%R(coefficient))

    html.table(rootlist, header=["Original root", "Perturbed root", "Distance"])
</div></li>
<li><p>Review of key concepts from linear algebra (see exercises).</p></li>
</ol>
<h2 id="aug-2012-1"><a href="#TOC">29 Aug 2012</a></h2>
<ol>
<li><p>Present the rest of Exercise 1.1–1.3</p></li>
<li><p>Discuss the connection between matrices and linear transformations, including invertible matrices.</p></li>
<li><p>Discuss coordinates briefly.</p></li>
</ol>
<h2 id="sep-2012"><a href="#TOC">05 Sep 2012</a></h2>
<ol>
<li><p>Present the rest of the exercises for Lecture 1</p></li>
<li><p>Complex numbers</p></li>
<li><p>Start working on exercises for Lecture 2.</p></li>
</ol>
</div>
<div class="mainmatter">
<h1 id="lecture-1"><a href="#TOC">Lecture 1</a></h1>
<p>This should primarily be a review of concepts from the first linear algebra class, though there are probably examples you haven’t seen before.</p>
<p>Practice interpreting the summation notation, like in equation 1.1 and in other places in the chapter. This book uses such summation notation a lot.</p>
<div class="definition">
<p>A <span class="term">linear combination</span> of some vectors is a sum of scalar multiples of the vectors (i.e., \(c_1\vec v_1+c_2\vec v_2+\cdots+c_n\vec v_n\)). A <span class="term">nontrival linear combination</span> is a linear combination with at least one nonzero scalar coefficient.</p>
<p>The <span class="term">span</span> of some vectors is the set of all linear combinations of the vectors (this is a set of vectors). A set of vectors is <span class="term">linearly independent</span> if none of the vectors can be written as a linear combination of the others. Equivalently, a set of vectors \(\{\vec v_1, \vec v_2, \ldots, \vec v_n\}\) is <span class="term">linearly independent</span> if there is any nontrivial linear combination that equals the zero vector (i.e., there is some nonzero coefficients \(c_i\) so that \(c_1\vec v_1+c_2\vec v_2+\cdots +c_n\vec v_n=\vec 0\)).</p>
A <span class="term">vector space</span> is the span of some vectors. Equivalently, a <span class="term">vector space</span> is a set of vectors that is closed under linear combinations (i.e., any linear combinations of any vectors in the set are always also in the set). A <span class="term">basis</span> for a vector space is a linearly independent set of vectors that spans the space. The <span class="term">dimension</span> of the space is the size of a basis (all bases of a space have the same size).
</div>

<div class="exercise"> 
<p>Which of the following sets of vectors are vector spaces? If not, give a reason why it is not (i.e., take some vectors in the set, and give a linear combination of those vectors that is not in the set). For each vector space, give two different bases and the dimension of the vector space.</p>
<ol>
<li>\(\{ (1,2,3)\}\)</li>
<li>\(\{c(-1,0,1)+(2,1,3)\mid c\in\mathbb{R}\}\)</li>
<li>\(\{(x,y) \mid x\geq 0 \text{ and } y\geq 0\}\): all vectors in \(\mathbb{R}^2\) that have only positive components</li>
<li>\(\{(x,y)\mid x=0 \text{ or } y=0\}\): all vectors in \(\mathbb{R}^2\) that are on either the \(x\) or \(y\) axes</li>
<li>\(\{(x,y,z)\mid \sqrt{x^2+y^2+z^2}\leq 1\}\): all vectors in \(\mathbb{R}^3\) that have length less than or equal to 1</li>
<li>\(\{c(1,2,3) \mid c\in\mathbb{R}\}\): all multiples (i.e., linear combinations) of the vector \((1,2,3)\). The endpoints of these vectors form a line through the origin.</li>
<li>\(\{(0,0,0)\}\): just the zero vector (i.e., all linear combinations of the zero vector). This vector space has only one vector, as opposed to the others which have an infinite number of vectors.</li>
<li>\(\{c_1(-1,0,1)+c_2(2,1,2) \mid c_1,c_2\in\mathbb{R}\}\): all linear combinations of \((-1,0,1)\) and \((2,1,2)\). The endpoints of these vectors form a plane through the origin.</li>
<li>\(\{c_1(-1,0,1)+c_2(2,1,2)+c_3(-4,-1,0) \mid c_1,c_2,c_3\in\mathbb{R}\}\): all linear combinations of \((-1,0,1)\), \((2,1,2)\), and \((-4,-1,0)\). Hint: Since the third vector \((-4,-1,0)\) is actually a linear combination of \((-1,0,1)\) and \((2,1,2)\), \((-4,-1,0)=2(-1,0,1)-(2,1,2)\), any linear combination of the three vectors can actually be written as a linear combination of just the first two vectors. For example,
</li>
<li>The set of all polynomials with degree at most 3.</li>
<li>The set of all polynomials with degree equal to 3.</li>
<li>The set of all polynomials.</li>
<li>The set of all 2 by 2 matrices.</li>
<li>The set of all invertible 3 by 3 matrices.</li>
<li>The set of all diagonal 3 by 3 matrices.</li>
<li>The set of all 3 by 3 matrices that are upper triangular.</li>
<li>The set of all 3 by 3 symmetric matrices.</li>
<li>The set of all continuous functions.</li>
<li>The set of all continuous functions such that \(f(0)=0\).</li>
<li>The set of all functions with continuous first derivatives.</li>
</ol>
</div>

<div class="definition">
<p>A linear transformation \(T\colon V\to W\) is a function from one vector space to another that:</p>
<ul>
<li>preserves vector addition: \(T(\vec x+\vec y) = T(\vec x)+T(\vec y)\)</li>
<li>preserves scalar multiplication: \(T(c\vec x) = cT(\vec x)\).</li>
</ul>
</div>

<div class="exercise">
    
Let \(A\) be a matrix. Prove that \(T(\vec x)=A\vec x\) is a linear transformation. [Hint: show that it satisfies the two criteria for a linear transformation at the bottom of page 3 of the text.]
</div>

<div class="exercise">
Find the matrix \(A\) for the linear transformation \(T((a,b)) = (2a-3b, 5a)\) so that \(T(\vec x)=A\vec x\).
</div>


<p>You can check your work with Sage (and also see how Sage creates vectors and matrices) by playing with the example below. Go ahead and change the matrix to your matrix.</p>
<div class="asagecell">
var('a,b')
v=vector([a,b])
A=matrix(QQ,[[1,2],[3,4]])
print A
print A*v
</div>
<p>When you get to this point, ask me to help you draw a diagram connecting the column space and null space of a matrix \(A\) and the linear transformation \(T(\vec x)=A\vec x\).</p>
<div class="exercise">
Show that linear transformations preserve linear combinations. In other words, show that if \(T\) is a linear transformation, then \[T(c_1\vec v_1+c_2\vec v_2+\cdots+c_n\vec v_n) = c_1T(\vec v_1)+c_2 T(\vec v_2)+\cdots+c_n T(\vec v_n).\]
</div>

<div class="exercise"> 
Suppose \(T\colon \mathbb{R}^2\to \mathbb{R}^2\) is a linear transformation. Suppose also that \(\vec u,\vec v\in\mathbb{R}^2\). Suppose also that \(T(\vec u)=(1,2)\) and \(T(\vec v)=(-3,4)\). What is \(T(3\vec u+2\vec v)\)?
</div>

<div class="exercise">
<p>Suppose \(T\colon \mathbb{R}^2\to \mathbb{R}^2\) is a linear transformation that does the following operations in order:</p>
<ol>
<li>rotates vectors by 90 degrees clockwise, then</li>
<li>flips the vectors over the \(y\) axis, then</li>
<li>stretches things horizontally by a factor of 3.</li>
</ol>
<p>Answer the following questions:</p>
<ol style="list-style-type: lower-alpha">
<li>What is \(T((1,0))\)?</li>
<li>What is \(T((0,1))\)?</li>
<li>What is \(T(3(1,0)+2(0,1))\)?</li>
<li>What is \(T((a,b))\)?</li>
<li>What is the matrix \(A\) representing \(T\), so that \(T(\vec x)=A\vec x\)?</li>
</ol>
</div>

<p>Check your work to the above exercise by modifying \(A\) and \(\vec v\) below and confirming your answers in the first parts of the problem.</p>
<div class="asagecell">
v=vector([1,2])
A=matrix(QQ,[[1,2],[3,4]])
print A*v
</div>
<div class="definition"> 
A <span class="term">coordinate vector</span> \([\vec v]_\mathcal{B}\) relative to an ordered basis \(\mathcal{B}\) is a vector of coefficients of the linear combination of basis elements equaling \(\vec v\). In other words, if \(\mathcal{B}=\{b_1,b_2,\ldots,b_n\}\) is a basis, then the coordinate vector for a vector \(\vec v=c_1\vec b_1+c_2\vec b_2+\cdots+c_n\vec b_n\) is \([\vec v]_\mathcal{B}=(c_1,c_2,\ldots,c_n)_\mathcal{B}\).
</div>

<div class="exercise"> 
<p>Let \(\mathcal{B}=\{1,x,x^2\}\) be a basis for \(P_2\), the set of all polynomials with degree at most 2.</p>
<ol>
<li>Let \(p=2x-x^2\) be a vector in \(P_3\). What is the coordinate vector \([p]_\mathcal{B}\)?</li>
<li>What is the polynomial represented by the coordinate vector \((2,3,-4)_\mathcal{B}\)?</li>
</ol>
</div>


<p>One of the huge advantages of using coordinate vectors is that linear transformations on finite dimensional vector spaces can be computed by multiplying a matrix and a coordinate vector.</p>
<div class="exercise">
\(P_3\) is the vector space of polynomials with degree at most 3. Let \(T\colon P_3\to\mathbb{R}^3\) be the linear transformation \(T(p)=(p(x=-1), p(x=0), p(x=1))\) (i.e., evaluate \(p\) at \(x=-1\), \(x=0\), and \(x=1\)). For example, \(T(3+x-2x^2+5x^3)=(3-1-2-5, 3, 3+1-2+5)=(-5,3,7)\). Let \(\mathcal{B}=\{1,x,x^2,x^3\}\) be a basis for \(P_3\). Find a matrix representing \(T\) relative to \(\mathcal{B}\) and the standard basis on \(\mathbb{R}^3\).
</div>

<div class="asagecell">
v=vector([3,1,-2,5])
#fill in A
A=matrix(QQ, [[],[],[]])
A*v # should be (-5,3,7), according to our example above.
</div>
<div class="exercise">
Write \(A\begin{pmatrix} 1\\2\\3\end{pmatrix}\) as a linear combination of the columns of \(A\).
</div>

<div class="exercise">
<p>Express \(AB\) as:</p>
<ol>
<li>a linear combination of columns of \(A\)</li>
<li>a linear combination of rows of \(B\).</li>
<li>dot products of rows of \(A\) and columns of \(B\).</li>
<li>What if \(B\) is a matrix of all ones? What does \(AB\) compute then? What does \(BA\) compute?</li>
</ol>
</div>
<p>Check your answer to the last part of the question above about an all-ones matrix.</p>
<div class="asagecell">
A=random_matrix(QQ, 3);
B=ones_matrix(QQ,3)
print A
print
print A*B
</div>
<div class="exercise">
Give short reasons why the text’s Theorem 1.3 parts (a), (b), (c), and (d) are equivalent.
</div>

<div class="exercise">
<p>Let \[A=\begin{bmatrix}1&amp;3\\2&amp;5\end{bmatrix},\quad
A^{-1}=\begin{bmatrix}-5&amp;3\\2&amp;-1\end{bmatrix}.\] Let \(\mathcal{B}=\{(1,2),\, (3,5)\}\) be a basis for \(\mathbb{R}^2\).</p>
<ol>
<li><p>Use \(A\) to compute the vectors with coordinate vectors \((1,0)_\mathcal{B}\), \((0,1)_\mathcal{B}\), and \((2,3)_\mathcal{B}\).</p></li>
<li><p>Use \(A^{-1}\) to compute the coordinate vectors \([(-3,-4)]_\mathcal{B}\) and \([(a,b)]_\mathcal{B}\).</p></li>
</ol>
</div>

<p>When you get to this point, ask me to help you modify the diagram we drew above in order to deal with linear transformations that correspond to invertible matrices.</p>
<div class="exercise">
Text exercise 1.1
</div>

<div class="exercise">
Text exercise 1.3
</div>

<div class="exercise">
Text exercise 1.4
</div>


<h1 id="draft-lecture-2-orthogonal-vectors-and-matrices"><a href="#TOC">(DRAFT) Lecture 2: Orthogonal Vectors and Matrices</a></h1>
<p>The set of complex numbers is denoted \(\mathbb{C}\). The conjugate of the complex number \(z=a+bi\) is \(\bar z = a-bi\).</p>
<h2 id="in-class-activities"><a href="#TOC">In-class activities</a></h2>

<div class="exercise">
Show that if \(z\bar z = z^2\), then \(z\) must be a real number (i.e., the imaginary part of \(z\) is 0).
</div>

<div class="exercise">
<p>Answer the following.</p>
<ol>
<li>Let \(A=\begin{bmatrix}4&amp;4+i&amp;2+i\\1-i&amp;2-i&amp;5\end{bmatrix}\). What is \(A^*\)? Is \(A\) hermitian?</li>
<li>Let \(B=\begin{bmatrix}2&amp;4+2i\\4-2i&amp;5\end{bmatrix}\). What is \(B^*\)? Is \(B\) hermitian?</li>
</ol>
</div>

<div class="exercise">

<p>Answer the following.</p>
<ol>
<li>What must be true about diagonal entries of hermitian matrices?</li>
<li>Prove that \(AA^*\) is always hermitian.</li>
</ol>
</div>

<div class="asagecell">
# Use CDF for complex matrices
A=matrix(CDF, [[4,4+I,2+I],[1-I,2-I,5]])
print A.H # this is A^*
print A.is_hermitian()
print A.H==A
</div>
<div class="exercise">
Give an example showing that the inner product on \(\mathbb{C}^2\) is bilinear. [Hint: compute explicitly each side of the 3 defining equations defining bilinearity.]
</div>

<div class="exercise">
Give an example showing that the (2,1) element of \((AB)^*\) is the same as the (2,1) element of \(B^*A^*\).
</div>

<div class="exercise">
<p>Answer the following.</p>
<ol>
<li>Prove that \((AB)^{-1}=B^{-1}A^{-1}\).</li>
<li>Prove that \((A^*)^{-1}=(A^{-1})^*\).</li>
</ol>
</div>

<div class="exercise">
<p>Answer the following.</p>
<ol>
<li>What is the angle between \((1,2)\) and \((2,-1)\)? Are these vectors orthogonal? [Hint: use equation (2.3) for the first question.]</li>
<li>Is the set \(\{(1/\sqrt{2}, i/\sqrt{2}), (1+i,-1)\}\) orthonormal? Is it linearly independent? Remember that now, scalars can be complex numbers.</li>
</ol>
</div>

<div class="exercise">
Give the reasons why the second equality in equation (2.7) in the text is true.
</div>

<div class="exercise">
Use the Sage cell below, or the Sage notebook, to compute the two decompositions of \(v\) given in equation (2.7).
</div>



<div class="asagecell">
A=matrix(RDF, [[1,4,3],[2,3,6],[-1,-4,3]])
Q,R=A.QR()

# check that Q is unitary, or in other words, that the columns of Q are
# an orthonormal basis.

(q1,q2,q3) = Q.columns()


# nicer columns
q1=vector(QQ,[2,-2,1])/3
q2=vector(QQ,[2,1,-2])/3
q1=vector(QQ,[1,2,2])/3

</div>
<div class="exercise">
Text exercise 2.1
</div>

<div class="exercise">
Text exercise 2.2
</div>

<div class="exercise">
Text exercise 2.3
</div>

<div class="exercise">
Text exercise 2.4. Additionally, what can be said about the determinant of a unitary matrix?
</div>

<div class="exercise"> 
Prove that if \(\lambda\) is an eigenvalue of \(A\) with eigenvector \(\vec x\), then \(\lambda^2\) is an eigenvalue of \(A^2\) with the same eigenvector \(\vec x\). [Hint: in mathematical notation, if \(A\vec x=\lambda x\) for some nonzero vector \(\vec x\), then show that \(A^2\vec x = \lambda^2 x\)].
</div>

<div class="exercise">
Text exercise 2.5
</div>

<div class="exercise">
Text exercise 2.6
</div>

<div class="exercise">
Text exercise 2.7
</div>

</div>
</body>
</html>
